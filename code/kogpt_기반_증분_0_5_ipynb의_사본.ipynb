{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KorStats/skku/blob/main/code/kogpt_%EA%B8%B0%EB%B0%98_%EC%A6%9D%EB%B6%84_0_5_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZCwLbgYSEy9",
        "outputId": "57c850d3-3f8b-4305-8208-87f5f8b22dc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/207.5 MB\u001b[0m \u001b[31m194.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# 모델 및 토크나이저 로드\n",
        "MODEL_NAME = \"skt/kogpt2-base-v2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# PAD 토큰 설정\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "# 5개의 프롬프트 템플릿 (각각 변수로 저장)\n",
        "prompt1 = \"다음 문장을 다른 표현으로 바꿔 주세요: {}\"\n",
        "prompt2 = \"비슷한 내용을 가진 새로운 문장을 만들어 주세요: {}\"\n",
        "prompt3 = \"주어진 문장을 좀 더 자연스럽고 상세하게 만들어 주세요: {}\"\n",
        "prompt4 = \"다음 문장을 20자 이내로 요약해 주세요: {}\"\n",
        "prompt5 = \"다음 문장을 100자 이상으로 확장해 주세요: {}\"\n",
        "\n",
        "# 데이터 증강 함수 정의\n",
        "def generate_augmented_texts(prompt, max_length=100):\n",
        "    # 5개의 프롬프트 각각 적용\n",
        "    formatted_prompts = [\n",
        "        prompt1.format(prompt),\n",
        "        prompt2.format(prompt),\n",
        "        prompt3.format(prompt),\n",
        "        prompt4.format(prompt),\n",
        "        prompt5.format(prompt)\n",
        "    ]\n",
        "\n",
        "    generated_texts = []\n",
        "\n",
        "    for final_prompt in formatted_prompts:\n",
        "        encoding = tokenizer(final_prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n",
        "        input_ids = encoding.input_ids.to(model.device)\n",
        "        attention_mask = encoding.attention_mask.to(model.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model.generate(\n",
        "                input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                max_new_tokens=30,\n",
        "                temperature=0.5,\n",
        "                top_p=0.8,\n",
        "                do_sample=True,\n",
        "                early_stopping=True,\n",
        "                repetition_penalty=1.2\n",
        "            )\n",
        "\n",
        "        generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "        generated_texts.append(generated_text)\n",
        "\n",
        "    # 각각 변수로 저장\n",
        "    generated_text1, generated_text2, generated_text3, generated_text4, generated_text5 = generated_texts\n",
        "\n",
        "    return generated_text1, generated_text2, generated_text3, generated_text4, generated_text5"
      ],
      "metadata": {
        "id": "fzQ99n61vYlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y-myI9BiUZ2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1jPHvcigUZ5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFo6hBMlsXSG"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!ln -s /content/gdrive/My\\ Drive/ /mydrive\n",
        "!ls /mydrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LRXjqd36sdtD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/My Drive/졸업논문/DATA/NSMC_0.5_증분대상_2500개.csv', encoding='utf-8-sig')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "oe6nTrV8vQ0F",
        "outputId": "dba814e3-575a-430a-9c96-c83f94c192fc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id                                           document  label   길이\n",
              "0  7652286  솔직히 이영화때문에 슈퍼맨시리즈가 7년이란 세월동안 묻혀있엇다 맨오브스틸은 미국에서...      0  138\n",
              "1  8895340  아무리 짱짱맨 옵대장의 다때려부수는 CG가 좋다그래도 이딴 디워랑 견줄만한 스토리로...      0  101\n",
              "2  6549317  오프닝장면 죠스영화 고대루 베겼네?? 여자 비명 연기하는 것도 고대루네~! 그냥 갖...      0  103"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-61abbaed-3198-4c7f-b7e1-5f24a210a4d7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "      <th>길이</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7652286</td>\n",
              "      <td>솔직히 이영화때문에 슈퍼맨시리즈가 7년이란 세월동안 묻혀있엇다 맨오브스틸은 미국에서...</td>\n",
              "      <td>0</td>\n",
              "      <td>138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8895340</td>\n",
              "      <td>아무리 짱짱맨 옵대장의 다때려부수는 CG가 좋다그래도 이딴 디워랑 견줄만한 스토리로...</td>\n",
              "      <td>0</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6549317</td>\n",
              "      <td>오프닝장면 죠스영화 고대루 베겼네?? 여자 비명 연기하는 것도 고대루네~! 그냥 갖...</td>\n",
              "      <td>0</td>\n",
              "      <td>103</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61abbaed-3198-4c7f-b7e1-5f24a210a4d7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-61abbaed-3198-4c7f-b7e1-5f24a210a4d7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-61abbaed-3198-4c7f-b7e1-5f24a210a4d7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ceec6176-391f-475f-a3c7-12dfc7e25a6e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ceec6176-391f-475f-a3c7-12dfc7e25a6e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ceec6176-391f-475f-a3c7-12dfc7e25a6e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2500,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1064808,\n        \"min\": 3913442,\n        \"max\": 10276810,\n        \"num_unique_values\": 2500,\n        \"samples\": [\n          8771283,\n          8384589,\n          9849229\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"document\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2500,\n        \"samples\": [\n          \"\\uac78\\ub808\\ucc98\\ub7fc \\uc0ac\\ub294\\uac8c \\uac10\\ub3d9\\uc801\\uc774\\uace0 \\uc544\\ub984\\ub2e4\\uc6b4 \\uc0ac\\ub791? \\uc0ac\\ub791\\ud0c0\\ub839 \\uadf8\\ub9cc \\ud574\\ub77c \\uadf8\\ub0e5 \\uc139\\uc2a4\\ud558\\uace0 \\uc2f6\\uc740\\uac70\\uc9c0 \\ubb34\\uc2a8 \\uc0ac\\ub791\\uc774\\ub0d0. \\uc694\\uc998 \\uac19\\uc774 \\ubb38\\ub780\\ud55c \\uc2dc\\ub300\\uc5d0 \\uc9c4\\uc2e4\\ud55c \\uc0ac\\ub791\\uc740 \\uc5c6\\ub2e4. \\uc774 \\uc138\\uc0c1\\uc740 \\uc8fc\\uc9c0\\uc721\\ub9bc\\uc758 \\uc2dc\\ub300. \\uc139\\uc2a4\\ub97c \\uc0ac\\ub791\\uc774\\ub780 \\ub2e8\\uc5b4\\ub85c \\uac10\\ud788 \\ud3ec\\uc7a5\\ud558\\uc9c0\\ub9c8\\ub77c. \\uc0ac\\ub791\\uc774\\ub780 \\ub2e8\\uc5b4\\uc5d0 \\ub300\\ud55c \\ubaa8\\uc695\\uc774\\ub2e4.\",\n          \"\\uc8fc\\uc778\\uacf5 \\uac10\\uc815\\ubcc0\\ud654\\uc5d0 \\ub300\\ud55c \\uacf5\\uac10\\uc774 \\ubd80\\uc871\\ud558\\uace0 \\uc5b5\\uc9c0\\ubc18\\uc804\\uc5d0 \\uc5b4\\uc774\\uc5c6\\ub294 \\ud5db\\uc6c3\\uc74c\\ub9cc \\ub098\\uc62c\\ubfd0.... \\uc131\\ud589\\uc704 \\uc7a5\\uba74\\uc774 \\ub108\\ubb34 \\ub354\\ub7fd\\uace0 \\uc2f8\\uad6c\\ub824\\ud2f1\\ud558\\ub2e4. \\uc5ec\\ubc30\\uc6b0 \\ud0a4\\ub3c4\\ud06c\\uace0 \\ub298\\uc52c\\ube75\\ube75\\ud55c\\ub370 \\ud654\\uc7a5\\uc774 \\ub108\\ubb34 \\uc774\\uc0c1\\ud574 90\\ub144\\ub300 \\ucd0c\\ube68\\uc791\\ub82c ..\\uadf8\\ub798\\ub3c4 \\ube44\\ub514\\uc624\\uc6a9 \\uc601\\ud654\\uce58\\uace4 \\uad1c\\ucc2e\\uc740\\ud3b8\\uc5d0 \\uc18d\\ud55c\\ub2e4.\",\n          \"\\uac1c\\uc5f0\\uc131 \\ub178\\ub2f5..\\uadf8 \\ub9ce\\uc740\\ub370\\uc5d0 \\uce74\\uba54\\ub77c \\ub2e4 \\uc124\\uce58\\ud55c\\uac83\\ub3c4 \\ub9d0\\ub3c4\\uc548\\ub418\\uace0, \\ubc30\\uac00\\ubc1c\\uacac\\ub41c\\uac70\\ub3c4 \\uc758\\uc2ec\\uc2a4\\ub7ec\\uc6b4\\ub370.\\uadf8\\uac78 \\ub610 \\ud0c0\\uace0\\uac00\\uc11cOOO \\uc9c4\\uc9dc \\uad6c\\uc131\\ub825\\uc5b4\\uc124\\ud504\\ub2e4. \\uc2ed\\uc5b5\\uc740\\uc65c\\uc900\\uac70\\uc9c0.. \\uc81c\\uc77c\\ub098\\uc05c\\ub188\\uc740 \\ud55c\\uae30\\ud0dc\\ub791 \\uc7a5\\ubbfc\\ucca0\\uc774\\ub124\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uae38\\uc774\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 23,\n        \"min\": 71,\n        \"max\": 144,\n        \"num_unique_values\": 73,\n        \"samples\": [\n          137\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터프레임에 적용\n",
        "df[['prompt1', 'prompt2', 'prompt3', 'prompt4', 'prompt5']] = df['document'].apply(lambda x: pd.Series(generate_augmented_texts(x, max_length=100)))\n",
        "\n",
        "# 결과 확인"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THHZlDNNs4fo",
        "outputId": "4a0e8e35-80f9-42f2-fb34-84f37a63d344"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:676: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('kogpt증분완료_0.5.csv', encoding='utf-8-sig')"
      ],
      "metadata": {
        "id": "oLThpg76s4iN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "iZCSRueqMojW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4yWwSjOkvvoN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# 모델 및 토크나이저 로드\n",
        "MODEL_NAME = \"skt/kogpt2-base-v2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# PAD 토큰 설정\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "# 5개의 프롬프트 템플릿\n",
        "prompt1 = \"다음 문장을 다른 표현으로 바꿔 주세요: {}\"\n",
        "prompt2 = \"비슷한 내용을 가진 새로운 문장을 만들어 주세요: {}\"\n",
        "prompt3 = \"주어진 문장을 좀 더 자연스럽고 상세하게 만들어 주세요: {}\"\n",
        "prompt4 = \"다음 문장을 20자 이내로 요약해 주세요: {}\"\n",
        "prompt5 = \"다음 문장을 100자 이상으로 확장해 주세요: {}\"\n",
        "\n",
        "# 데이터 증강 함수 정의\n",
        "def generate_augmented_texts(prompt, num_samples=2):\n",
        "    \"\"\" 한 문장에 대해 5개의 프롬프트를 적용하고, 각 프롬프트당 num_samples개의 문장을 생성 \"\"\"\n",
        "    formatted_prompts = [\n",
        "        prompt1.format(prompt),\n",
        "        prompt2.format(prompt),\n",
        "        prompt3.format(prompt),\n",
        "        prompt4.format(prompt),\n",
        "        prompt5.format(prompt)\n",
        "    ]\n",
        "\n",
        "    generated_texts = []\n",
        "\n",
        "    for final_prompt in formatted_prompts:\n",
        "        encoding = tokenizer(final_prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "        input_ids = encoding.input_ids.to(model.device)\n",
        "        attention_mask = encoding.attention_mask.to(model.device)\n",
        "\n",
        "        for _ in range(num_samples):  # 각 프롬프트당 num_samples개의 문장 생성\n",
        "            with torch.no_grad():\n",
        "                output = model.generate(\n",
        "                    input_ids,\n",
        "                    attention_mask=attention_mask,\n",
        "                    max_new_tokens=30,  # `max_length` 대신 `max_new_tokens`\n",
        "                    temperature=0.5,\n",
        "                    top_p=0.8,\n",
        "                    do_sample=True,\n",
        "                    repetition_penalty=1.2\n",
        "                )\n",
        "\n",
        "            generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "            generated_texts.append(generated_text)\n",
        "\n",
        "    return generated_texts  # 10개의 문장 리스트 반환"
      ],
      "metadata": {
        "id": "0YK_T_onvvql"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "RGfVMRsivAzw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/My Drive/졸업논문/DATA/NSMC_0.1_증분대상_500개.csv', encoding='utf-8-sig')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[['aug1', 'aug2', 'aug3', 'aug4', 'aug5', 'aug6', 'aug7', 'aug8', 'aug9', 'aug10']] = df['document'].apply(lambda x: pd.Series(generate_augmented_texts(x, num_samples=2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wS-PyxdIBXGy",
        "outputId": "012555fc-9fda-46f5-d390-24c47c8e4592"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('/content/gdrive/MyDrive/My Drive/졸업논문/kogpt증분완료_0.1.csv', encoding='utf-8-sig')"
      ],
      "metadata": {
        "id": "N_Sepu6aBXJH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rTkoguZyBlRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# 모델 및 토크나이저 로드\n",
        "MODEL_NAME = \"skt/kogpt2-base-v2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# PAD 토큰 설정\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "# 5개의 프롬프트 템플릿\n",
        "prompt1 = \"다음 문장을 다른 표현으로 바꿔 주세요: {}\"\n",
        "prompt2 = \"비슷한 내용을 가진 새로운 문장을 만들어 주세요: {}\"\n",
        "prompt3 = \"주어진 문장을 좀 더 자연스럽고 상세하게 만들어 주세요: {}\"\n",
        "prompt4 = \"다음 문장을 20자 이내로 요약해 주세요: {}\"\n",
        "prompt5 = \"다음 문장을 100자 이상으로 확장해 주세요: {}\"\n",
        "\n",
        "# 데이터 증강 함수 정의\n",
        "def generate_augmented_texts(prompt, num_samples=10):\n",
        "    \"\"\" 한 문장에 대해 5개의 프롬프트를 적용하고, 각 프롬프트당 num_samples개의 문장을 생성 \"\"\"\n",
        "    formatted_prompts = [\n",
        "        prompt1.format(prompt),\n",
        "        prompt2.format(prompt),\n",
        "        prompt3.format(prompt),\n",
        "        prompt4.format(prompt),\n",
        "        prompt5.format(prompt)\n",
        "    ]\n",
        "\n",
        "    generated_texts = []\n",
        "\n",
        "    for final_prompt in formatted_prompts:\n",
        "        encoding = tokenizer(final_prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "        input_ids = encoding.input_ids.to(model.device)\n",
        "        attention_mask = encoding.attention_mask.to(model.device)\n",
        "\n",
        "        for _ in range(num_samples):  # 각 프롬프트당 num_samples개의 문장 생성\n",
        "            with torch.no_grad():\n",
        "                output = model.generate(\n",
        "                    input_ids,\n",
        "                    attention_mask=attention_mask,\n",
        "                    max_new_tokens=30,  # `max_length` 대신 `max_new_tokens`\n",
        "                    temperature=0.5,\n",
        "                    top_p=0.8,\n",
        "                    do_sample=True,\n",
        "                    repetition_penalty=1.2\n",
        "                )\n",
        "\n",
        "            generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "            generated_texts.append(generated_text)\n",
        "\n",
        "    return generated_texts  # 50개의 문장 리스트 반환"
      ],
      "metadata": {
        "id": "RBGMLMU4Blm4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/My Drive/졸업논문/DATA/NSMC_0.02_증분대상100개.csv', encoding='utf-8-sig')"
      ],
      "metadata": {
        "id": "OETZW85pBlpY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[[f'aug{i+1}' for i in range(50)]] = df['document'].apply(lambda x: pd.Series(generate_augmented_texts(x, num_samples=10)))"
      ],
      "metadata": {
        "id": "sW6q3bjtCV1F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97beb8a4-8eae-41e3-a616-2c77a21e0876"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('kogpt증분완료_0.02.csv', encoding='utf-8-sig')"
      ],
      "metadata": {
        "id": "Wsh709ATCWKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z9T3QRkhCWMX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}